{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b914430",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f476e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "querry = \"#delmonte\"\n",
    "tweets = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a435a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "    if i >= tweets:\n",
    "         break\n",
    "            tweets_list.append([tweet.date, tweet.rawContent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pdDataFrame(tweets_list, columns=['date', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('delmonte.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df=pd.read_csv('delmonte.csv')\n",
    "print(tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54599d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nlkt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7988\\3405391044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnlkt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'punkt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlkt' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nlkt.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4d358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
